{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exceptional-hunger",
   "metadata": {
    "id": "exceptional-hunger"
   },
   "source": [
    "# Machine Learning\n",
    "## Programming Assignment 6: Naive Bayes\n",
    "\n",
    "Instructions:\n",
    "The aim of this assignment is to give you hands-on experience with a real-life machine learning application.\n",
    "You will be analyzing the sentiment of reviews using Naive Bayes classification.\n",
    "You can only use the Python programming language and Jupyter Notebooks.\n",
    "Please use procedural programming style and comment your code thoroughly.\n",
    "There are two parts of this assignment. In part 1, you can use NumPy, Pandas, Matplotlib, and any other standard Python libraries. You are not allowed to use NLTK, scikit-learn, or any other machine learning toolkit. You can only use scikit-learn in part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-brooks",
   "metadata": {
    "id": "alive-brooks"
   },
   "source": [
    "### Part 1: Implementing Naive Bayes classifier from scratch (60 points)\n",
    "\n",
    "You are not allowed to use scikit-learn or any other machine learning toolkit for this part. You have to implement your own Naive Bayes classifier from scratch. You may use Pandas, NumPy, Matplotlib, and other standard Python libraries.\n",
    "\n",
    "#### Problem:\n",
    "The purpose of this assignment is to get you familiar with Naive Bayes classification. The core dataset contains 50,000 reviews split evenly into 25k train and 25k test sets. The overall distribution of labels is balanced (25k pos and 25k neg). There are two top-level directories [train/, test/] corresponding to the training and test sets. Each contains [pos/, neg/] directories for the reviews with binary labels positive and negative. Within these directories, reviews are stored in text files named following the convention [[id]_[rating].txt] where [id] is a unique id and [rating] is the star rating for that review on a 1-10 scale. For example, the file [test/pos/200_8.txt] is the text for a positive-labeled testset example with unique id 200 and star rating 8/10 from IMDb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "solid-placement",
   "metadata": {
    "id": "solid-placement"
   },
   "outputs": [],
   "source": [
    "## Here are the libraries you will need for this part/\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.spatial as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educated-bandwidth",
   "metadata": {
    "id": "educated-bandwidth"
   },
   "source": [
    "#### Task 1.1: Dataset (5 points)\n",
    "Your task is to read the dataset and stopwords file into a useful data structure. Print out a few reviews and a few items from the stop word list, succesfully being able to do this will earn you 5 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indoor-prediction",
   "metadata": {
    "id": "indoor-prediction"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Train Positive Review:\n",
      " Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school life, such as \"Teachers\". My 35 years in the teaching profession lead me to believe that Bromwell High's satire is much closer to reality than is \"Teachers\". The scramble to survive financially, the insightful students who can see right through their pathetic teachers' pomp, the pettiness of the whole situation, all remind me of the schools I knew and their students. When I saw the episode in which a student repeatedly tried to burn down the school, I immediately recalled ......... at .......... High. A classic line: INSPECTOR: I'm here to sack one of your teachers. STUDENT: Welcome to Bromwell High. I expect that many adults of my age think that Bromwell High is far fetched. What a pity that it isn't!\n",
      "\n",
      "Sample Train Negative Review:\n",
      " Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a terrific example of absurd comedy. A formal orchestra audience is turned into an insane, violent mob by the crazy chantings of it's singers. Unfortunately it stays absurd the WHOLE time with no general narrative eventually making it just too off putting. Even those from the era should be turned off. The cryptic dialogue would make Shakespeare seem easy to a third grader. On a technical level it's better than you might think with some good cinematography by future great Vilmos Zsigmond. Future stars Sally Kirkland and Frederic Forrest can be seen briefly.\n",
      "\n",
      "Sample Test Positive Review:\n",
      " I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\n",
      "\n",
      "Sample Test Negative Review:\n",
      " Once again Mr. Costner has dragged out a movie for far longer than necessary. Aside from the terrific sea rescue sequences, of which there are very few I just did not care about any of the characters. Most of us have ghosts in the closet, and Costner's character are realized early on, and then forgotten until much later, by which time I did not care. The character we should really care about is a very cocky, overconfident Ashton Kutcher. The problem is he comes off as kid who thinks he's better than anyone else around him and shows no signs of a cluttered closet. His only obstacle appears to be winning over Costner. Finally when we are well past the half way point of this stinker, Costner tells us all about Kutcher's ghosts. We are told why Kutcher is driven to be the best with no prior inkling or foreshadowing. No magic here, it was all I could do to keep from turning it off an hour in.\n",
      "\n",
      "Sample Stop Words:  ['i', \"i'm\", 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Function to read files from directory\n",
    "def read_reviews(directory):\n",
    "    reviews = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            with open(os.path.join(directory, filename), 'r', encoding='utf-8') as file:\n",
    "                reviews.append(file.read())\n",
    "    return reviews\n",
    "\n",
    "# Reading stop words\n",
    "def read_stopwords(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        stopwords = file.read().splitlines()\n",
    "    return stopwords\n",
    "\n",
    "train_pos_reviews = read_reviews('C:/Users/HP/Desktop/Naive Bayes Data/train/pos')\n",
    "train_neg_reviews = read_reviews('C:/Users/HP/Desktop/Naive Bayes Data/train/pos/neg')\n",
    "test_pos_reviews = read_reviews('C:/Users/HP/Desktop/Naive Bayes Data/test/pos')\n",
    "test_neg_reviews = read_reviews('C:/Users/HP/Desktop/Naive Bayes Data/test/neg')\n",
    "stopwords = read_stopwords('stop_words.txt')\n",
    "\n",
    "print(\"Sample Train Positive Review:\\n\", train_pos_reviews[0])\n",
    "print(\"\\nSample Train Negative Review:\\n\", train_neg_reviews[0])\n",
    "print(\"\\nSample Test Positive Review:\\n\", test_pos_reviews[0])\n",
    "print(\"\\nSample Test Negative Review:\\n\", test_neg_reviews[0])\n",
    "print(\"\\nSample Stop Words: \", stopwords[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-reminder",
   "metadata": {
    "id": "ignored-reminder"
   },
   "source": [
    "#### Task 1.2: Data Preprocessing (10 points)\n",
    "\n",
    "In the preprocessing step, youâ€™re required to remove the stop words, punctuation marks, numbers, unwanted symbols, hyperlinks, and usernames from the tweets and convert them to lower case. You may find the string and regex module useful for this purpose. Use the stop word list provided within the assignment.\n",
    "\n",
    "Print out a few random reviews from your dataset, if they conform to the rules mentioned above, you will gain 10 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hydraulic-patch",
   "metadata": {
    "id": "hydraulic-patch"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Cleaned Positive Review:\n",
      " bromwell high cartoon comedy ran time programs school life teachers years teaching profession lead believe bromwell highs satire much closer reality teachers scramble survive financially insightful students see right pathetic teachers pomp pettiness whole situation remind schools knew students saw episode student repeatedly tried burn school immediately recalled high classic line inspector im sack one teachers student welcome bromwell high expect many adults age think bromwell high far fetched pity isnt\n",
      "\n",
      "Sample Cleaned Negative Review:\n",
      " story man unnatural feelings pig starts opening scene terrific example absurd comedy formal orchestra audience turned insane violent mob crazy chantings singers unfortunately stays absurd whole time general narrative eventually making putting even era turned cryptic dialogue would make shakespeare seem easy third grader technical level better might think good cinematography future great vilmos zsigmond future stars sally kirkland frederic forrest seen briefly\n",
      "\n",
      "Sample Cleaned Positive Review:\n",
      " bromwell high cartoon comedy ran time programs school life teachers years teaching profession lead believe bromwell highs satire much closer reality teachers scramble survive financially insightful students see right pathetic teachers pomp pettiness whole situation remind schools knew students saw episode student repeatedly tried burn school immediately recalled high classic line inspector im sack one teachers student welcome bromwell high expect many adults age think bromwell high far fetched pity isnt\n",
      "\n",
      "Sample Cleaned Negative Review:\n",
      " story man unnatural feelings pig starts opening scene terrific example absurd comedy formal orchestra audience turned insane violent mob crazy chantings singers unfortunately stays absurd whole time general narrative eventually making putting even era turned cryptic dialogue would make shakespeare seem easy third grader technical level better might think good cinematography future great vilmos zsigmond future stars sally kirkland frederic forrest seen briefly\n"
     ]
    }
   ],
   "source": [
    "# Function to preprocess reviews\n",
    "def preprocess_review(review, stopwords):\n",
    "    # Convert to lowercase\n",
    "    review = review.lower()  \n",
    "    # Remove punctuation, numbers, and symbols\n",
    "    review = re.sub(r'[^a-z\\s]', '', review)  \n",
    "    # Tokenize the review\n",
    "    words = review.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    \n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Preprocessing\n",
    "train_pos_reviews_cleaned = [preprocess_review(review, stopwords) for review in train_pos_reviews]\n",
    "train_neg_reviews_cleaned = [preprocess_review(review, stopwords) for review in train_neg_reviews]\n",
    "test_pos_reviews_cleaned = [preprocess_review(review, stopwords) for review in test_pos_reviews]\n",
    "test_neg_reviews_cleaned = [preprocess_review(review, stopwords) for review in test_neg_reviews]\n",
    "\n",
    "# Display cleaned reviews\n",
    "print(\"Sample Cleaned Positive Review:\\n\", train_pos_reviews_cleaned[0])\n",
    "print(\"\\nSample Cleaned Negative Review:\\n\", train_neg_reviews_cleaned[0])\n",
    "print(\"\\nSample Cleaned Positive Review:\\n\", train_pos_reviews_cleaned[0])\n",
    "print(\"\\nSample Cleaned Negative Review:\\n\", train_neg_reviews_cleaned[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-potato",
   "metadata": {
    "id": "impossible-potato"
   },
   "source": [
    "#### Task 1.3: Splitting the dataset (5 points)\n",
    "\n",
    "In this part, divide the given dataset into training and testing sets based on an 80-20 split using python.\n",
    "Print out the sizes of the training dataset and test dataset, training data should contain 40000 reviews and test data should contain 10000 reviews. If your sizes are correct, you get full points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f076df4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Positive Reviews: 12500\n",
      "Training Negative Reviews: 12500\n",
      "Test Positive Reviews: 12500\n",
      "Test Negative Reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "# Print lengths of positive and negative reviews for train and test sets\n",
    "print(\"Training Positive Reviews:\", len(train_pos_reviews_cleaned))\n",
    "print(\"Training Negative Reviews:\", len(train_neg_reviews_cleaned))\n",
    "\n",
    "print(\"Test Positive Reviews:\", len(test_pos_reviews_cleaned))\n",
    "print(\"Test Negative Reviews:\", len(test_neg_reviews_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "relevant-episode",
   "metadata": {
    "id": "relevant-episode"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size (80%): 40000\n",
      "Test Data Size (20%): 10000\n"
     ]
    }
   ],
   "source": [
    "# Labels:\n",
    "# 1 for positive\n",
    "# 0 for negative\n",
    "train_labels = [1] * len(train_pos_reviews_cleaned) + [0] * len(train_neg_reviews_cleaned)\n",
    "test_labels = [1] * len(test_pos_reviews_cleaned) + [0] * len(test_neg_reviews_cleaned)\n",
    "\n",
    "train_data = train_labels + test_labels[0: 15000]\n",
    "test_data = test_labels[15000: 25000]\n",
    "\n",
    "print(\"Training Data Size (80%):\", len(train_data)) # train_labels = 40000\n",
    "print(\"Test Data Size (20%):\", len(test_data)) # test_labels = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "julian-venice",
   "metadata": {
    "id": "julian-venice"
   },
   "source": [
    "#### Task 1.4: Create Naive Bayes classifier (30 points)\n",
    "\n",
    "You will create your own Naive Neighbors classifier function by implementing the following algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59032f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 117710\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# to build vocabulary and word frequency\n",
    "def build_vocabulary(reviews):\n",
    "    word_freq = defaultdict(int)\n",
    "    for review in reviews:\n",
    "        words = review.split()\n",
    "        for word in words:\n",
    "            word_freq[word] += 1\n",
    "    return word_freq\n",
    "\n",
    "pos_word_freq = build_vocabulary(train_pos_reviews_cleaned)\n",
    "neg_word_freq = build_vocabulary(train_neg_reviews_cleaned)\n",
    "\n",
    "total_pos_words = sum(pos_word_freq.values())\n",
    "total_neg_words = sum(neg_word_freq.values())\n",
    "\n",
    "vocabulary = set(list(pos_word_freq.keys()) + list(neg_word_freq.keys()))\n",
    "print(\"Vocabulary Size:\", len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6a393e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Positive): 0.5\n",
      "P(Negative): 0.5\n"
     ]
    }
   ],
   "source": [
    "# Calculate prior probabilities\n",
    "P_positive = len(train_pos_reviews_cleaned) / (len(train_pos_reviews_cleaned) + len(train_neg_reviews_cleaned))\n",
    "P_negative = len(train_neg_reviews_cleaned) / (len(train_pos_reviews_cleaned) + len(train_neg_reviews_cleaned))\n",
    "\n",
    "print(\"P(Positive):\", P_positive)\n",
    "print(\"P(Negative):\", P_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfd30534",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "\n",
    "def calculate_word_likelihood(word_freq, total_words, vocabulary_size, word):\n",
    "    return (word_freq[word] + alpha) / (total_words + alpha * vocabulary_size)\n",
    "def calculate_log_likelihood(review, word_freq, total_words, vocabulary_size):\n",
    "    log_likelihood = 0\n",
    "    words = review.split()\n",
    "    for word in words:\n",
    "        if word in vocabulary:  # Only consider words in vocabulary\n",
    "            log_likelihood += np.log(calculate_word_likelihood(word_freq, total_words, vocabulary_size, word))\n",
    "    return log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b9802c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to classify\n",
    "\n",
    "def classify_review(review):\n",
    "    pos_log_likelihood = np.log(P_positive) + calculate_log_likelihood(review, pos_word_freq, total_pos_words, len(vocabulary))\n",
    "    neg_log_likelihood = np.log(P_negative) + calculate_log_likelihood(review, neg_word_freq, total_neg_words, len(vocabulary))\n",
    "    \n",
    "    if pos_log_likelihood > neg_log_likelihood:\n",
    "        return 1  # Positive\n",
    "    else:\n",
    "        return 0  # Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9706fb87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test data: 0.82456\n"
     ]
    }
   ],
   "source": [
    "# Classify all test data\n",
    "\n",
    "predicted_labels = [classify_review(review) for review in test_pos_reviews_cleaned + test_neg_reviews_cleaned]\n",
    "\n",
    "# Calculate accuracy\n",
    "def calculate_accuracy(predicted, actual):\n",
    "    correct = sum(p == a for p, a in zip(predicted, actual))\n",
    "    return correct / len(actual)\n",
    "\n",
    "# Accuracy on the test set\n",
    "accuracy = calculate_accuracy(predicted_labels, test_labels)\n",
    "print(\"Accuracy on Test data:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-equivalent",
   "metadata": {
    "id": "durable-equivalent"
   },
   "source": [
    "#### Task 1.5: Implement evaluation functions (10 points)\n",
    "\n",
    "Implement evaluation functions that calculates the:\n",
    "- classification accuracy,\n",
    "- F1 score,\n",
    "- and the confusion matrix\n",
    "of your classifier on the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a944bf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate classification accuracy\n",
    "\n",
    "def calculate_accuracy(predicted, actual):\n",
    "    correct = sum(p == a for p, a in zip(predicted, actual))\n",
    "    return correct / len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b06f68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate confusion matrix\n",
    "\n",
    "def calculate_confusion_matrix(predicted, actual):\n",
    "    TP = FP = TN = FN = 0\n",
    "    for p, a in zip(predicted, actual):\n",
    "        if p == 1 and a == 1:\n",
    "            TP += 1\n",
    "        elif p == 1 and a == 0:\n",
    "            FP += 1\n",
    "        elif p == 0 and a == 0:\n",
    "            TN += 1\n",
    "        elif p == 0 and a == 1:\n",
    "            FN += 1\n",
    "    return TP, FP, TN, FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9b209ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.46%\n",
      "Confusion Matrix:\n",
      "TP: 9616, FP: 1502, TN: 10998, FN: 2884\n",
      "Precision: 0.86, Recall: 0.77, F1 Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# calculate F1 Score, Precision, and Recall\n",
    "\n",
    "def calculate_f1_score(predicted, actual):\n",
    "    TP, FP, TN, FN = calculate_confusion_matrix(predicted, actual)\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) != 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
    "\n",
    "    return precision, recall, f1_score\n",
    "\n",
    "predicted_labels = [classify_review(review) for review in test_pos_reviews_cleaned + test_neg_reviews_cleaned]\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(predicted_labels, test_labels)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "TP, FP, TN, FN = calculate_confusion_matrix(predicted_labels, test_labels)\n",
    "print(f\"Confusion Matrix:\\nTP: {TP}, FP: {FP}, TN: {TN}, FN: {FN}\")\n",
    "\n",
    "# Calculate Precision, Recall, and F1 Score\n",
    "precision, recall, f1 = calculate_f1_score(predicted_labels, test_labels)\n",
    "print(f\"Precision: {precision:.2f}, Recall: {recall:.2f}, F1 Score: {f1:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "angry-diversity",
   "metadata": {
    "id": "angry-diversity"
   },
   "source": [
    "### Part 2:  Naive Bayes classifier using scikit-learn (40 points)\n",
    "\n",
    "In this part, use scikit-learnâ€™s CountVectorizer to transform your train and test set to bag-of-words representation and NaÃ¯ve Bayes implementation to train and test the NaÃ¯ve Bayes on the provided dataset. Use scikit-learnâ€™s accuracy_score function to calculate the accuracy and confusion_matrix function to calculate the confusion matrix on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "intelligent-fundamental",
   "metadata": {
    "id": "intelligent-fundamental"
   },
   "outputs": [],
   "source": [
    "# Here are the libraries and specific functions you will be needing for this part\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02406803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used Pre Processed data in 'train_pos_reviews_cleaned' worked in Task#1\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "\n",
    "X_train = vectorizer.fit_transform(train_pos_reviews_cleaned + train_neg_reviews_cleaned)\n",
    "X_test = vectorizer.transform(test_pos_reviews_cleaned + test_neg_reviews_cleaned)\n",
    "\n",
    "# Labels: 1 for positive, 0 for negative\n",
    "y_train = [1] * len(train_pos_reviews_cleaned) + [0] * len(train_neg_reviews_cleaned)\n",
    "y_test = [1] * len(test_pos_reviews_cleaned) + [0] * len(test_neg_reviews_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5d8b783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "nb_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5eed8162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the labels for the test set\n",
    "y_pred = nb_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d9757782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 82.44%\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[10994  1506]\n",
      " [ 2885  9615]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.79      0.88      0.83     12500\n",
      "    Positive       0.86      0.77      0.81     12500\n",
      "\n",
      "    accuracy                           0.82     25000\n",
      "   macro avg       0.83      0.82      0.82     25000\n",
      "weighted avg       0.83      0.82      0.82     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on the test set\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\\n\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification report (Includes Precision, Recall, F1 Score)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Negative\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93af9631",
   "metadata": {},
   "source": [
    "*****I got the same accuracy with implementation using scratch and using standard sklearn python library. It means my alorithms are working fine.*****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825e61cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
